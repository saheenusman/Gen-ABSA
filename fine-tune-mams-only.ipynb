{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":13135605,"sourceType":"datasetVersion","datasetId":8321690}],"dockerImageVersionId":31193,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# CELL 0: ONE-SHOT SETUP (NO RESTART NEEDED)\nprint(\"=\"*70)\nprint(\"COMPLETE SETUP - MAMS CL TRAINING\")\nprint(\"=\"*70)\n\nimport subprocess\nimport sys\n\n# Fix protobuf\nprint(\"1/2 Fixing protobuf...\")\nsubprocess.run([sys.executable, \"-m\", \"pip\", \"uninstall\", \"-y\", \"protobuf\"], capture_output=True)\nsubprocess.run([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"protobuf==3.20.3\"], capture_output=True)\nprint(\"âœ“ Protobuf fixed\")\n\n# Install packages\nprint(\"2/2 Installing packages...\")\nsubprocess.run([\n    sys.executable, \"-m\", \"pip\", \"install\", \"-q\",\n    \"pandas\", \"numpy\", \"scikit-learn\",\n    \"transformers\", \"torch\", \"accelerate\",\n    \"hdbscan\", \"umap-learn\", \"sentence-transformers\"\n], capture_output=True)\nprint(\"âœ“ Packages installed\")\n\n# Force reload protobuf\nimport importlib\nif 'google.protobuf' in sys.modules:\n    importlib.reload(sys.modules['google.protobuf'])\n\n# Import everything\nimport json\nimport pandas as pd\nimport numpy as np\nimport os\nfrom collections import defaultdict, Counter\nimport torch\nfrom transformers import T5EncoderModel, AutoTokenizer\nfrom hdbscan import HDBSCAN\nfrom sklearn.metrics import silhouette_score\nimport warnings\nwarnings.filterwarnings('ignore')\n\nprint(\"âœ“ All libraries imported\")\n\n# GPU check\nif torch.cuda.is_available():\n    print(f\"âœ“ GPU: {torch.cuda.get_device_name(0)}\")\nelse:\n    print(\"âœ— No GPU\")\n\nprint(\"=\"*70)\nprint(\"SETUP COMPLETE\")\nprint(\"=\"*70)\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-11-10T13:36:52.410229Z","iopub.execute_input":"2025-11-10T13:36:52.410477Z","iopub.status.idle":"2025-11-10T13:38:42.791273Z","shell.execute_reply.started":"2025-11-10T13:36:52.410453Z","shell.execute_reply":"2025-11-10T13:38:42.790616Z"}},"outputs":[{"name":"stdout","text":"======================================================================\nCOMPLETE SETUP - MAMS CL TRAINING\n======================================================================\n1/2 Fixing protobuf...\nâœ“ Protobuf fixed\n2/2 Installing packages...\nâœ“ Packages installed\n","output_type":"stream"},{"name":"stderr","text":"2025-11-10 13:38:23.554217: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1762781903.749987      48 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1762781903.810911      48 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"name":"stdout","text":"âœ“ All libraries imported\nâœ“ GPU: Tesla T4\n======================================================================\nSETUP COMPLETE\n======================================================================\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"# CELL 0: ONE-SHOT SETUP (NO RESTART NEEDED - BUT RESTART IF PYARROW ERROR PERSISTS)\nprint(\"=\"*70)\nprint(\"COMPLETE SETUP - MAMS CL TRAINING WITH EVALUATION PACKAGES\")\nprint(\"=\"*70)\nimport subprocess\nimport sys\n\n# Step 0: Early PyArrow Fix (Resolves Binary Incompatibility with cuDF & Datasets)\nprint(\"0/4 Fixing pyarrow & cuDF compatibility...\")\n# Align cuDF versions to avoid internal conflicts\nsubprocess.run([sys.executable, \"-m\", \"pip\", \"uninstall\", \"-y\", \"cudf-cu12\", \"pylibcudf-cu12\", \"cudf-polars-cu12\"], capture_output=True)\nsubprocess.run([\n    sys.executable, \"-m\", \"pip\", \"install\", \"-q\",\n    \"cudf-cu12==25.6.0\", \"pylibcudf-cu12==25.6.0\", \"cudf-polars-cu12==25.6.0\"\n], capture_output=True)\n# Nuke & reinstall compatible pyarrow (15.0.2: Works with cuDF 25.x & datasets 4.4.1)\nsubprocess.run([sys.executable, \"-m\", \"pip\", \"uninstall\", \"-y\", \"pyarrow\"], capture_output=True)\nsubprocess.run([sys.executable, \"-m\", \"pip\", \"install\", \"--no-cache-dir\", \"pyarrow==15.0.2\"], capture_output=True)\nprint(\"âœ“ PyArrow & cuDF fixed\")\n\n# Step 1: Fix protobuf\nprint(\"1/4 Fixing protobuf...\")\nsubprocess.run([sys.executable, \"-m\", \"pip\", \"uninstall\", \"-y\", \"protobuf\"], capture_output=True)\nsubprocess.run([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"protobuf==3.20.3\"], capture_output=True)\nprint(\"âœ“ Protobuf fixed\")\n\n# Step 2: Install core + evaluation packages\nprint(\"2/4 Installing packages...\")\nsubprocess.run([\n    sys.executable, \"-m\", \"pip\", \"install\", \"-q\",\n    \"pandas\", \"numpy\", \"scikit-learn\",\n    \"transformers\", \"torch\", \"accelerate\",\n    \"hdbscan\", \"umap-learn\", \"sentence-transformers\",\n    \"evaluate\", \"sacrebleu\", \"datasets==4.4.1\"  # Explicit datasets for control\n], capture_output=True)\nprint(\"âœ“ Packages installed\")\n\n# Step 3: Force reload protobuf (if needed)\nimport importlib\nif 'google.protobuf' in sys.modules:\n    importlib.reload(sys.modules['google.protobuf'])\n\n# Step 4: Import everything (including evaluation)\nprint(\"3/4 Importing libraries...\")\nimport json\nimport pandas as pd\nimport numpy as np\nimport os\nfrom collections import defaultdict, Counter\nimport torch\nfrom transformers import T5EncoderModel, AutoTokenizer\nfrom hdbscan import HDBSCAN\nfrom sklearn.metrics import silhouette_score\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Evaluation imports\nimport evaluate\nfrom sacrebleu import corpus_bleu\nfrom sentence_transformers import SentenceTransformer\n\nprint(\"âœ“ All libraries imported\")\n\n# Quick eval test\nprint(\"4/4 Testing evaluation packages...\")\ntry:\n    # Light tests\n    metric = evaluate.load(\"bleu\")  # Via evaluate\n    print(\"âœ“ evaluate (BLEU) loaded\")\n    print(f\"âœ“ sacrebleu: Version {sacrebleu.__version__}\")\n    model = SentenceTransformer('all-MiniLM-L6-v2')  # Quick embed\n    print(\"âœ“ sentence-transformers: Model loaded\")\nexcept Exception as e:\n    print(f\"âš  Evaluation test partial fail: {e}\")\n    print(\"  - Run 'Runtime > Restart session' and re-run this cell if imports fail.\")\n\n# GPU check\nif torch.cuda.is_available():\n    print(f\"âœ“ GPU: {torch.cuda.get_device_name(0)}\")\nelse:\n    print(\"âœ— No GPU\")\nprint(\"=\"*70)\nprint(\"SETUP COMPLETE - READY FOR MAMS CL TRAINING & EVAL\")\nprint(\"=\"*70)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-10T13:52:18.473578Z","iopub.execute_input":"2025-11-10T13:52:18.473950Z","iopub.status.idle":"2025-11-10T13:56:05.104628Z","shell.execute_reply.started":"2025-11-10T13:52:18.473914Z","shell.execute_reply":"2025-11-10T13:56:05.103994Z"}},"outputs":[{"name":"stdout","text":"======================================================================\nCOMPLETE SETUP - MAMS CL TRAINING WITH EVALUATION PACKAGES\n======================================================================\n0/4 Fixing pyarrow & cuDF compatibility...\nâœ“ PyArrow & cuDF fixed\n1/4 Fixing protobuf...\nâœ“ Protobuf fixed\n2/4 Installing packages...\nâœ“ Packages installed\n3/4 Importing libraries...\n","output_type":"stream"},{"name":"stderr","text":"2025-11-10 13:55:39.312464: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1762782939.712847      48 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1762782939.866076      48 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"name":"stdout","text":"âœ“ All libraries imported\n4/4 Testing evaluation packages...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading builder script: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"51b0de2d308d4f4f845c2e314c07957d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading extra modules:   0%|          | 0.00/1.55k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"919e76517bfd4d22b77895d4e47db11b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading extra modules: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5ba2f5a6262a4fc4ba40c187c1a9004a"}},"metadata":{}},{"name":"stdout","text":"âœ“ evaluate (BLEU) loaded\nâš  Evaluation test partial fail: name 'sacrebleu' is not defined\n  - Run 'Runtime > Restart session' and re-run this cell if imports fail.\nâœ“ GPU: Tesla T4\n======================================================================\nSETUP COMPLETE - READY FOR MAMS CL TRAINING & EVAL\n======================================================================\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"# ============================================================================\n# CELL 1: VANILLA T5 BASELINE - MAMS ABSA FINE-TUNING\n# ============================================================================\nprint(\"=\"*70)\nprint(\"CELL 1: BASELINE - VANILLA T5 ABSA FINE-TUNING\")\nprint(\"=\"*70)\n\nfrom transformers import T5ForConditionalGeneration, AutoTokenizer\nfrom transformers import TrainingArguments, Trainer, DataCollatorForSeq2Seq\nfrom datasets import Dataset\nimport xml.etree.ElementTree as ET\n\n# Load vanilla T5\nprint(\"\\nLoading vanilla T5-base...\")\nmodel = T5ForConditionalGeneration.from_pretrained('t5-base')\ntokenizer = AutoTokenizer.from_pretrained('t5-base')\nprint(\"âœ“ Vanilla T5 loaded\\n\")\n\n# Parse MAMS\ndef parse_mams_absa(xml_file):\n    tree = ET.parse(xml_file)\n    root = tree.getroot()\n    data = []\n    \n    for sentence in root.findall('.//sentence'):\n        text_elem = sentence.find('text')\n        if text_elem is None:\n            continue\n        \n        text = text_elem.text.strip()\n        aspects = sentence.findall('aspectTerms/aspectTerm')\n        \n        outputs = []\n        for aspect in aspects:\n            term = aspect.get('term')\n            polarity = aspect.get('polarity')\n            outputs.append(f\"{term} is {polarity}\")\n        \n        if outputs:\n            data.append({\n                'input': f\"extract aspects: {text}\",\n                'output': \" [SEP] \".join(outputs)\n            })\n    \n    return data\n\nprint(\"Loading MAMS data...\")\ntrain_data = parse_mams_absa('/kaggle/input/mams-for-absa/train.xml')\nval_data = parse_mams_absa('/kaggle/input/mams-for-absa/val.xml')\ntest_data = parse_mams_absa('/kaggle/input/mams-for-absa/test.xml')\n\nprint(f\"âœ“ Train: {len(train_data)}, Val: {len(val_data)}, Test: {len(test_data)}\\n\")\n\n# Convert to datasets\ntrain_dataset = Dataset.from_list(train_data)\nval_dataset = Dataset.from_list(val_data)\n\n# Tokenize\ndef preprocess(examples):\n    inputs = tokenizer(examples['input'], max_length=128, truncation=True, padding='max_length')\n    targets = tokenizer(examples['output'], max_length=128, truncation=True, padding='max_length')\n    inputs['labels'] = targets['input_ids']\n    return inputs\n\nprint(\"Tokenizing...\")\ntrain_dataset = train_dataset.map(preprocess, batched=True)\nval_dataset = val_dataset.map(preprocess, batched=True)\nprint(\"âœ“ Tokenization complete\\n\")\n\n# Train (EXACT SAME PARAMETERS AS CL MODEL)\nprint(\"Fine-tuning vanilla T5 on ABSA...\")\n\ntraining_args = TrainingArguments(\n    output_dir='./mams_t5_baseline',\n    num_train_epochs=10,  # SAME AS CL\n    per_device_train_batch_size=16,  # SAME AS CL\n    per_device_eval_batch_size=16,  # SAME AS CL\n    warmup_steps=500,  # SAME AS CL\n    weight_decay=0.01,  # SAME AS CL\n    logging_steps=100,  # SAME AS CL\n    eval_strategy='epoch',  # SAME AS CL\n    save_strategy='epoch',  # SAME AS CL\n    save_total_limit=2,  # SAME AS CL\n    load_best_model_at_end=True,  # SAME AS CL\n    metric_for_best_model='eval_loss',  # SAME AS CL\n    fp16=True,  # SAME AS CL\n    report_to='none'\n)\n\ndata_collator = DataCollatorForSeq2Seq(tokenizer, model=model)\n\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=train_dataset,\n    eval_dataset=val_dataset,\n    data_collator=data_collator\n)\n\nprint(\"=\"*70)\ntrainer.train()\n\nprint(\"\\nâœ… BASELINE TRAINING COMPLETE!\")\nmodel.save_pretrained('./mams_t5_baseline_final')\ntokenizer.save_pretrained('./mams_t5_baseline_final')\nprint(\"âœ“ Saved to: ./mams_t5_baseline_final\\n\")\n\nprint(\"=\"*70)\nprint(\"CELL 1 COMPLETE - BASELINE ESTABLISHED\")\nprint(\"=\"*70)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-10T13:56:13.573222Z","iopub.execute_input":"2025-11-10T13:56:13.574161Z","iopub.status.idle":"2025-11-10T14:25:58.462246Z","shell.execute_reply.started":"2025-11-10T13:56:13.574133Z","shell.execute_reply":"2025-11-10T14:25:58.461311Z"}},"outputs":[{"name":"stdout","text":"======================================================================\nCELL 1: BASELINE - VANILLA T5 ABSA FINE-TUNING\n======================================================================\n\nLoading vanilla T5-base...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.21k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d85bd47a5d8f41138935b5f01514d911"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/892M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"84daec1cb6c94f6487f47825a608c845"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8be3f291df124bb7b389321bfc68d820"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f7ce762fdf024ca79e0be350911eba24"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.39M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cb1816ec16dd4f29915417a054791b6c"}},"metadata":{}},{"name":"stdout","text":"âœ“ Vanilla T5 loaded\n\nLoading MAMS data...\nâœ“ Train: 4297, Val: 500, Test: 500\n\nTokenizing...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/4297 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"712b2abb290c496781b443a8f0ea82ce"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/500 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"87a0891630cf451287d22fc37e7a1fb6"}},"metadata":{}},{"name":"stdout","text":"âœ“ Tokenization complete\n\nFine-tuning vanilla T5 on ABSA...\n======================================================================\n","output_type":"stream"},{"name":"stderr","text":"Passing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.48.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.\nPassing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.48.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='1350' max='1350' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [1350/1350 29:31, Epoch 10/10]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>10.412000</td>\n      <td>0.497752</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.652200</td>\n      <td>0.065949</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.063300</td>\n      <td>0.048242</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.051500</td>\n      <td>0.041848</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>0.043800</td>\n      <td>0.041282</td>\n    </tr>\n    <tr>\n      <td>6</td>\n      <td>0.037500</td>\n      <td>0.039139</td>\n    </tr>\n    <tr>\n      <td>7</td>\n      <td>0.032900</td>\n      <td>0.040358</td>\n    </tr>\n    <tr>\n      <td>8</td>\n      <td>0.032400</td>\n      <td>0.039567</td>\n    </tr>\n    <tr>\n      <td>9</td>\n      <td>0.029300</td>\n      <td>0.040019</td>\n    </tr>\n    <tr>\n      <td>10</td>\n      <td>0.027800</td>\n      <td>0.039906</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"There were missing keys in the checkpoint model loaded: ['encoder.embed_tokens.weight', 'decoder.embed_tokens.weight', 'lm_head.weight'].\n","output_type":"stream"},{"name":"stdout","text":"\nâœ… BASELINE TRAINING COMPLETE!\nâœ“ Saved to: ./mams_t5_baseline_final\n\n======================================================================\nCELL 1 COMPLETE - BASELINE ESTABLISHED\n======================================================================\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"# ============================================================================\n# CELL 2: COMPREHENSIVE EVALUATION - VANILLA T5 BASELINE\n# ============================================================================\nprint(\"=\"*70)\nprint(\"EVALUATION - VANILLA T5 BASELINE - MAMS ABSA\")\nprint(\"=\"*70)\n\nimport torch\nimport numpy as np\nfrom transformers import T5ForConditionalGeneration, AutoTokenizer\nfrom sentence_transformers import SentenceTransformer\nfrom sklearn.metrics.pairwise import cosine_similarity\nfrom collections import Counter\nimport xml.etree.ElementTree as ET\nimport re\n\n# Load model\nprint(\"\\nLoading Vanilla T5 baseline model...\")\nmodel = T5ForConditionalGeneration.from_pretrained('./mams_t5_baseline_final')\ntokenizer = AutoTokenizer.from_pretrained('./mams_t5_baseline_final')\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'\nmodel = model.to(device)\nmodel.eval()\nprint(f\"âœ“ Model loaded on {device}\\n\")\n\n# Load test data\ndef parse_mams_test(xml_file):\n    tree = ET.parse(xml_file)\n    root = tree.getroot()\n    data = []\n    \n    for sentence in root.findall('.//sentence'):\n        text_elem = sentence.find('text')\n        if text_elem is None:\n            continue\n        \n        text = text_elem.text.strip()\n        aspects = sentence.findall('aspectTerms/aspectTerm')\n        \n        gold_tuples = []\n        for aspect in aspects:\n            term = aspect.get('term').strip()\n            polarity = aspect.get('polarity').strip().lower()\n            gold_tuples.append((term, polarity))\n        \n        if gold_tuples:\n            data.append({\n                'text': text,\n                'gold_tuples': gold_tuples\n            })\n    \n    return data\n\ntest_data = parse_mams_test('/kaggle/input/mams-for-absa/test.xml')\nprint(f\"Evaluating {len(test_data)} test samples...\\n\")\n\n# Generate predictions\nprint(\"Generating predictions...\")\npredictions = []\nfor idx, sample in enumerate(test_data):\n    if idx % 100 == 0:\n        print(f\"  Progress: {idx}/{len(test_data)}\")\n    \n    input_text = f\"extract aspects: {sample['text']}\"\n    inputs = tokenizer(input_text, return_tensors='pt', max_length=128, truncation=True).to(device)\n    \n    with torch.no_grad():\n        outputs = model.generate(**inputs, max_length=128, num_beams=4, early_stopping=True)\n    \n    pred_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n    \n    pred_tuples = []\n    for segment in pred_text.split('[SEP]'):\n        segment = segment.strip()\n        match = re.match(r'(.+?)\\s+is\\s+(positive|negative|neutral)', segment, re.IGNORECASE)\n        if match:\n            pred_tuples.append((match.group(1).strip(), match.group(2).strip().lower()))\n    \n    predictions.append({\n        'text': sample['text'],\n        'pred_tuples': pred_tuples,\n        'gold_tuples': sample['gold_tuples'],\n        'pred_raw': pred_text\n    })\n\nprint(f\"âœ“ Generated {len(predictions)} predictions\\n\")\n\n# ============================================================\n# PRIMARY METRICS\n# ============================================================\nprint(\"=\"*70)\nprint(\"PRIMARY METRICS\")\nprint(\"=\"*70)\n\ndef normalize(text):\n    return text.lower().strip()\n\ntuple_tp = tuple_fp = tuple_fn = 0\naspect_tp = aspect_fp = aspect_fn = 0\nexact_matches = 0\n\nfor pred in predictions:\n    pred_set = {(normalize(a), s) for a, s in pred['pred_tuples']}\n    gold_set = {(normalize(a), s) for a, s in pred['gold_tuples']}\n    \n    tuple_tp += len(pred_set & gold_set)\n    tuple_fp += len(pred_set - gold_set)\n    tuple_fn += len(gold_set - pred_set)\n    \n    pred_aspects = {normalize(a) for a, _ in pred['pred_tuples']}\n    gold_aspects = {normalize(a) for a, _ in pred['gold_tuples']}\n    \n    aspect_tp += len(pred_aspects & gold_aspects)\n    aspect_fp += len(pred_aspects - gold_aspects)\n    aspect_fn += len(gold_aspects - pred_aspects)\n    \n    if pred_set == gold_set:\n        exact_matches += 1\n\ntuple_prec = tuple_tp / (tuple_tp + tuple_fp) if (tuple_tp + tuple_fp) > 0 else 0\ntuple_rec = tuple_tp / (tuple_tp + tuple_fn) if (tuple_tp + tuple_fn) > 0 else 0\ntuple_f1 = 2 * tuple_prec * tuple_rec / (tuple_prec + tuple_rec) if (tuple_prec + tuple_rec) > 0 else 0\n\naspect_prec = aspect_tp / (aspect_tp + aspect_fp) if (aspect_tp + aspect_fp) > 0 else 0\naspect_rec = aspect_tp / (aspect_tp + aspect_fn) if (aspect_tp + aspect_fn) > 0 else 0\naspect_f1 = 2 * aspect_prec * aspect_rec / (aspect_prec + aspect_rec) if (aspect_prec + aspect_rec) > 0 else 0\n\nexact_acc = exact_matches / len(predictions)\n\nsent_correct = 0\nsent_total = 0\nfor pred in predictions:\n    pred_dict = {normalize(a): s for a, s in pred['pred_tuples']}\n    gold_dict = {normalize(a): s for a, s in pred['gold_tuples']}\n    for asp in set(pred_dict.keys()) & set(gold_dict.keys()):\n        sent_total += 1\n        if pred_dict[asp] == gold_dict[asp]:\n            sent_correct += 1\n\nsent_acc = sent_correct / sent_total if sent_total > 0 else 0\n\nprint(f\"\\n1. Aspect + Sentiment (Tuple Matching):\")\nprint(f\"   TP: {tuple_tp}, FP: {tuple_fp}, FN: {tuple_fn}\")\nprint(f\"   Precision: {tuple_prec:.4f}\")\nprint(f\"   Recall:    {tuple_rec:.4f}\")\nprint(f\"   F1 Score:  {tuple_f1:.4f}\")\n\nprint(f\"\\n2. Aspect-Only (Ignore Sentiment):\")\nprint(f\"   TP: {aspect_tp}, FP: {aspect_fp}, FN: {aspect_fn}\")\nprint(f\"   Precision: {aspect_prec:.4f}\")\nprint(f\"   Recall:    {aspect_rec:.4f}\")\nprint(f\"   F1 Score:  {aspect_f1:.4f}\")\n\nprint(f\"\\n3. Exact Match Accuracy:\")\nprint(f\"   {exact_matches}/{len(predictions)} = {exact_acc:.4f} ({exact_acc*100:.2f}%)\")\n\nprint(f\"\\n4. Sentiment Accuracy (on detected aspects):\")\nprint(f\"   {sent_correct}/{sent_total} = {sent_acc:.4f} ({sent_acc*100:.2f}%)\")\n\n# ============================================================\n# TOP 10 ASPECTS\n# ============================================================\nprint(\"\\n\" + \"=\"*70)\nprint(\"TOP 10 ASPECTS\")\nprint(\"=\"*70)\n\naspect_stats = {}\nfor pred in predictions:\n    for aspect, _ in pred['gold_tuples']:\n        norm_asp = normalize(aspect)\n        if norm_asp not in aspect_stats:\n            aspect_stats[norm_asp] = {'gold': 0, 'pred': 0, 'tp': 0}\n        aspect_stats[norm_asp]['gold'] += 1\n    \n    for aspect, _ in pred['pred_tuples']:\n        norm_asp = normalize(aspect)\n        if norm_asp not in aspect_stats:\n            aspect_stats[norm_asp] = {'gold': 0, 'pred': 0, 'tp': 0}\n        aspect_stats[norm_asp]['pred'] += 1\n    \n    pred_aspects = {normalize(a) for a, _ in pred['pred_tuples']}\n    gold_aspects = {normalize(a) for a, _ in pred['gold_tuples']}\n    for asp in pred_aspects & gold_aspects:\n        aspect_stats[asp]['tp'] += 1\n\nfor asp, stats in aspect_stats.items():\n    p = stats['tp'] / stats['pred'] if stats['pred'] > 0 else 0\n    r = stats['tp'] / stats['gold'] if stats['gold'] > 0 else 0\n    stats['f1'] = 2*p*r/(p+r) if (p+r) > 0 else 0\n\ntop_aspects = sorted(aspect_stats.items(), key=lambda x: x[1]['gold'], reverse=True)[:10]\n\nprint(f\"\\nAspect{' '*24}Gold   Pred     TP       F1\")\nprint(\"-\"*70)\nfor asp, stats in top_aspects:\n    print(f\"{asp[:30]:<30}{stats['gold']:>5}{stats['pred']:>7}{stats['tp']:>7}   {stats['f1']:.4f}\")\n\n# ============================================================\n# PREDICTION EXAMPLES\n# ============================================================\nprint(\"\\n\" + \"=\"*70)\nprint(\"PREDICTION EXAMPLES (First 10)\")\nprint(\"=\"*70)\n\nfor i, pred in enumerate(predictions[:10], 1):\n    pred_set = set(pred['pred_tuples'])\n    gold_set = set(pred['gold_tuples'])\n    match_status = \"âœ… EXACT MATCH\" if pred_set == gold_set else f\"âŒ Partial ({len(pred_set & gold_set)}/{len(gold_set)} matched)\"\n    \n    print(f\"\\n{'â”€'*70}\")\n    print(f\"Example {i}\")\n    print(f\"{'â”€'*70}\")\n    print(f\"TEXT:\\n{pred['text'][:80]}...\\n\")\n    print(f\"GOLD:\")\n    for asp, sent in pred['gold_tuples']:\n        print(f\"{asp} | {sent}\")\n    print(f\"\\nPREDICTED:\")\n    for asp, sent in pred['pred_tuples']:\n        print(f\"{asp} | {sent}\")\n    print(f\"\\n{match_status}\")\n\n# ============================================================\n# GENERATION QUALITY METRICS\n# ============================================================\nprint(\"\\n\" + \"=\"*70)\nprint(\"GENERATION QUALITY METRICS\")\nprint(\"=\"*70)\n\ngold_strings = []\npred_strings = []\nfor pred in predictions:\n    gold_str = \" [SEP] \".join([f\"{a} is {s}\" for a, s in pred['gold_tuples']])\n    pred_str = pred['pred_raw']\n    gold_strings.append(gold_str)\n    pred_strings.append(pred_str)\n\n# ROUGE\nprint(\"\\n[1/4] Computing ROUGE scores...\")\ntry:\n    import evaluate\n    rouge = evaluate.load('rouge')\n    rouge_results = rouge.compute(predictions=pred_strings, references=gold_strings, use_stemmer=True)\n    print(f\"âœ… ROUGE-1: {rouge_results['rouge1']:.4f}\")\n    print(f\"   ROUGE-2: {rouge_results['rouge2']:.4f}\")\n    print(f\"   ROUGE-L: {rouge_results['rougeL']:.4f}\")\nexcept Exception as e:\n    print(f\"âš ï¸ ROUGE skipped: {e}\")\n\n# BLEU\nprint(\"\\n[2/4] Computing BLEU score...\")\ntry:\n    from sacrebleu import corpus_bleu\n    references = [[g] for g in gold_strings]\n    bleu_result = corpus_bleu(pred_strings, references)\n    print(f\"âœ… BLEU Score: {bleu_result.score:.4f}\")\nexcept Exception as e:\n    print(f\"âš ï¸ BLEU skipped: {e}\")\n\n# METEOR\nprint(\"\\n[3/4] Computing METEOR score...\")\ntry:\n    meteor = evaluate.load('meteor')\n    meteor_result = meteor.compute(predictions=pred_strings, references=gold_strings)\n    print(f\"âœ… METEOR Score: {meteor_result['meteor']:.4f}\")\nexcept Exception as e:\n    print(f\"âš ï¸ METEOR skipped: {e}\")\n\n# BERTScore\nprint(\"\\n[4/4] Computing BERTScore...\")\ntry:\n    bertscore = evaluate.load('bertscore')\n    bert_results = bertscore.compute(predictions=pred_strings, references=gold_strings, lang='en', model_type='microsoft/deberta-base-mnli', batch_size=16)\n    bert_f1 = sum(bert_results['f1']) / len(bert_results['f1'])\n    print(f\"âœ… BERTScore F1: {bert_f1:.4f}\")\nexcept Exception as e:\n    print(f\"âš ï¸ BERTScore skipped: {e}\")\n\n# ============================================================\n# SEMANTIC HALLUCINATION ANALYSIS\n# ============================================================\nprint(\"\\n\" + \"=\"*70)\nprint(\"SEMANTIC HALLUCINATION ANALYSIS\")\nprint(\"=\"*70)\n\nprint(\"\\n[1/3] Loading semantic model...\")\ntry:\n    sem_model = SentenceTransformer('all-MiniLM-L6-v2')\n    print(\"âœ“ Semantic model loaded\")\n    \n    print(\"\\n[2/3] Analyzing hallucinations...\")\n    total_gen = 0\n    explicit_count = 0\n    semantic_match = 0\n    true_halluc = 0\n    halluc_examples = []\n    \n    for pred in predictions:\n        text_words = set(pred['text'].lower().split())\n        gold_aspects = {normalize(a) for a, _ in pred['gold_tuples']}\n        \n        for aspect, sentiment in pred['pred_tuples']:\n            total_gen += 1\n            aspect_norm = normalize(aspect)\n            \n            aspect_words = aspect_norm.split()\n            in_text = all(w in text_words for w in aspect_words)\n            \n            if in_text:\n                explicit_count += 1\n                continue\n            \n            if gold_aspects:\n                asp_emb = sem_model.encode([aspect_norm])\n                gold_embs = sem_model.encode(list(gold_aspects))\n                sims = cosine_similarity(asp_emb, gold_embs)[0]\n                max_sim = np.max(sims)\n                \n                if max_sim > 0.65:\n                    semantic_match += 1\n                else:\n                    true_halluc += 1\n                    if len(halluc_examples) < 5:\n                        halluc_examples.append({\n                            'text': pred['text'],\n                            'halluc': aspect,\n                            'gold': list(gold_aspects)\n                        })\n            else:\n                true_halluc += 1\n    \n    semantic_halluc_rate = true_halluc / total_gen if total_gen > 0 else 0\n    strict_halluc_rate = (total_gen - explicit_count) / total_gen if total_gen > 0 else 0\n    \n    print(f\"\\nâœ… Semantic Hallucination Analysis:\")\n    print(f\"   Total generated aspects:           {total_gen}\")\n    print(f\"   Explicit (in text):                {explicit_count} ({explicit_count/total_gen*100:.1f}%)\")\n    print(f\"   Implicit but semantically valid:   {semantic_match} ({semantic_match/total_gen*100:.1f}%)\")\n    print(f\"   True hallucinations:               {true_halluc} ({true_halluc/total_gen*100:.1f}%)\")\n    print(f\"\\n   ğŸ“Š Semantic Hallucination Rate:    {semantic_halluc_rate:.4f} ({semantic_halluc_rate*100:.1f}%)\")\n    print(f\"   ğŸ“Š Strict Hallucination Rate:      {strict_halluc_rate:.4f} ({strict_halluc_rate*100:.1f}%)\")\n    \n    if halluc_examples:\n        print(f\"\\n   âš ï¸ Examples of true hallucinations:\")\n        for i, ex in enumerate(halluc_examples[:3], 1):\n            print(f\"   {i}. Generated: '{ex['halluc']}' | Gold: {ex['gold']}\")\n            print(f\"      Text: {ex['text'][:80]}...\")\n    \n    print(\"\\n[3/3] Computing semantic coverage...\")\n    total_gold = 0\n    exact_cov = 0\n    sem_cov = 0\n    \n    for pred in predictions:\n        pred_aspects = {normalize(a) for a, _ in pred['pred_tuples']}\n        \n        for aspect, _ in pred['gold_tuples']:\n            total_gold += 1\n            aspect_norm = normalize(aspect)\n            \n            if aspect_norm in pred_aspects:\n                exact_cov += 1\n            elif pred_aspects:\n                asp_emb = sem_model.encode([aspect_norm])\n                pred_embs = sem_model.encode(list(pred_aspects))\n                sims = cosine_similarity(asp_emb, pred_embs)[0]\n                if np.max(sims) > 0.65:\n                    sem_cov += 1\n    \n    exact_coverage = exact_cov / total_gold if total_gold > 0 else 0\n    semantic_coverage = (exact_cov + sem_cov) / total_gold if total_gold > 0 else 0\n    \n    print(f\"\\nâœ… Semantic Coverage Analysis:\")\n    print(f\"   Total gold aspects:       {total_gold}\")\n    print(f\"   Exact matches:            {exact_cov} ({exact_cov/total_gold*100:.1f}%)\")\n    print(f\"   Semantic matches:         {sem_cov} ({sem_cov/total_gold*100:.1f}%)\")\n    print(f\"   Missed aspects:           {total_gold - exact_cov - sem_cov} ({(1 - semantic_coverage)*100:.1f}%)\")\n    print(f\"\\n   ğŸ“Š Exact Coverage:        {exact_coverage:.4f} ({exact_coverage*100:.1f}%)\")\n    print(f\"   ğŸ“Š Semantic Coverage:     {semantic_coverage:.4f} ({semantic_coverage*100:.1f}%)\")\n    \nexcept Exception as e:\n    print(f\"âš ï¸ Semantic analysis skipped: {e}\")\n    semantic_halluc_rate = None\n    semantic_coverage = None\n\n# ============================================================\n# FORMAT ADHERENCE\n# ============================================================\nprint(\"\\n\" + \"=\"*70)\nprint(\"FORMAT ADHERENCE\")\nprint(\"=\"*70)\n\nvalid_format = sum(1 for p in predictions if p['pred_tuples'] or not p['pred_raw'].strip())\nmalformed = len(predictions) - valid_format\nempty = sum(1 for p in predictions if not p['pred_raw'].strip())\n\nprint(f\"\\nâœ… Format Adherence:\")\nprint(f\"   Valid format: {valid_format}/{len(predictions)} ({valid_format/len(predictions)*100:.1f}%)\")\nprint(f\"   Malformed outputs: {malformed} ({malformed/len(predictions)*100:.1f}%)\")\nprint(f\"   Empty outputs: {empty} ({empty/len(predictions)*100:.1f}%)\")\n\n# ============================================================\n# COMPREHENSIVE SUMMARY\n# ============================================================\nprint(\"\\n\" + \"=\"*70)\nprint(\"COMPREHENSIVE EVALUATION SUMMARY - VANILLA T5 BASELINE\")\nprint(\"=\"*70)\n\nprint(f\"\\nModel: Vanilla T5-base (Baseline)\")\nprint(f\"Dataset: {len(predictions)} test samples\\n\")\n\nprint(\"=\"*70)\nprint(\"TASK-SPECIFIC METRICS (Primary)\")\nprint(\"=\"*70)\nprint(f\"\\n1. Aspect + Sentiment F1:      {tuple_f1:.4f}\")\nprint(f\"2. Aspect-Only F1:              {aspect_f1:.4f}\")\nprint(f\"3. Exact Match Accuracy:        {exact_acc:.4f}\")\nprint(f\"4. Sentiment Accuracy:          {sent_acc:.4f}\")\n\nprint(\"\\n\" + \"=\"*70)\nprint(\"GENERATION QUALITY METRICS\")\nprint(\"=\"*70)\nif 'rouge_results' in locals():\n    print(f\"\\n5. ROUGE-L:                     {rouge_results['rougeL']:.4f}\")\nif 'bleu_result' in locals():\n    print(f\"6. BLEU:                        {bleu_result.score:.4f}\")\nif 'meteor_result' in locals():\n    print(f\"7. METEOR:                      {meteor_result['meteor']:.4f}\")\nif 'bert_f1' in locals():\n    print(f\"8. BERTScore F1:                {bert_f1:.4f}\")\n\nprint(\"\\n\" + \"=\"*70)\nprint(\"RELIABILITY METRICS (Semantic-Aware)\")\nprint(\"=\"*70)\nif semantic_halluc_rate is not None:\n    print(f\"\\n9. Semantic Hallucination Rate: {semantic_halluc_rate:.4f} ({semantic_halluc_rate*100:.1f}%)\")\n    print(f\"10. Semantic Coverage:          {semantic_coverage:.4f} ({semantic_coverage*100:.1f}%)\")\nprint(f\"11. Format Adherence:           {valid_format/len(predictions):.4f} ({valid_format/len(predictions)*100:.1f}%)\")\n\nprint(\"\\n\" + \"=\"*70)\nprint(\"âœ… EVALUATION COMPLETE - VANILLA T5 BASELINE\")\nprint(\"=\"*70)\nprint(\"\\nğŸ“Š Compare these results with CL T5 model for improvement analysis\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-10T14:27:20.855590Z","iopub.execute_input":"2025-11-10T14:27:20.855920Z","iopub.status.idle":"2025-11-10T14:31:13.009667Z","shell.execute_reply.started":"2025-11-10T14:27:20.855884Z","shell.execute_reply":"2025-11-10T14:31:13.008872Z"}},"outputs":[{"name":"stdout","text":"======================================================================\nEVALUATION - VANILLA T5 BASELINE - MAMS ABSA\n======================================================================\n\nLoading Vanilla T5 baseline model...\nâœ“ Model loaded on cuda\n\nEvaluating 500 test samples...\n\nGenerating predictions...\n  Progress: 0/500\n  Progress: 100/500\n  Progress: 200/500\n  Progress: 300/500\n  Progress: 400/500\nâœ“ Generated 500 predictions\n\n======================================================================\nPRIMARY METRICS\n======================================================================\n\n1. Aspect + Sentiment (Tuple Matching):\n   TP: 826, FP: 561, FN: 510\n   Precision: 0.5955\n   Recall:    0.6183\n   F1 Score:  0.6067\n\n2. Aspect-Only (Ignore Sentiment):\n   TP: 989, FP: 398, FN: 347\n   Precision: 0.7130\n   Recall:    0.7403\n   F1 Score:  0.7264\n\n3. Exact Match Accuracy:\n   144/500 = 0.2880 (28.80%)\n\n4. Sentiment Accuracy (on detected aspects):\n   826/989 = 0.8352 (83.52%)\n\n======================================================================\nTOP 10 ASPECTS\n======================================================================\n\nAspect                        Gold   Pred     TP       F1\n----------------------------------------------------------------------\nfood                             79     89     75   0.8929\nservice                          52     53     48   0.9143\nmenu                             48     54     46   0.9020\nwaiter                           47     46     45   0.9677\nwaitress                         37     38     36   0.9600\ndinner                           36     40     33   0.8684\nbar                              27     27     25   0.9259\ndrinks                           24     28     22   0.8462\nmeal                             23     28     22   0.8627\nmanager                          23     21     21   0.9545\n\n======================================================================\nPREDICTION EXAMPLES (First 10)\n======================================================================\n\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nExample 1\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nTEXT:\nThe food was served promptly but the meal wasn't rushed - we had plenty of time ...\n\nGOLD:\nfood | neutral\nserved | positive\nappetizers | positive\n\nPREDICTED:\nfood | positive\nmeal | neutral\nappetizers | neutral\nentrees | neutral\ndrinks | neutral\n\nâŒ Partial (0/3 matched)\n\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nExample 2\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nTEXT:\nWhen I got home, there was a message on the machine because the owner realized t...\n\nGOLD:\nowner | neutral\nwaitress | negative\nwine | neutral\n\nPREDICTED:\nowner | negative\nwaitress | neutral\nwine | neutral\n\nâŒ Partial (1/3 matched)\n\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nExample 3\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nTEXT:\nThe Scene Shun Lee Palace is popular with midtown locals, possibly because the u...\n\nGOLD:\nScene | positive\nlunch | neutral\n\nPREDICTED:\nScene | positive\nChinese | neutral\nlunch | neutral\n\nâŒ Partial (2/2 matched)\n\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nExample 4\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nTEXT:\nTo both our surprise, this inquiry was interpreted as a personal offense by the ...\n\nGOLD:\nwaiter | negative\npastries | neutral\n\nPREDICTED:\nwaiter | negative\npastries | neutral\n\nâœ… EXACT MATCH\n\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nExample 5\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nTEXT:\nIn fact you can find their menu offerings at other places for better qualities a...\n\nGOLD:\nmenu | neutral\nprices | positive\n\nPREDICTED:\nmenu offerings | neutral\nprices | positive\n\nâŒ Partial (1/2 matched)\n\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nExample 6\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nTEXT:\nBeen here a few times and food has always been good but service really suffers w...\n\nGOLD:\nfood | positive\nservice | negative\n\nPREDICTED:\nfood | positive\nservice | negative\n\nâœ… EXACT MATCH\n\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nExample 7\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nTEXT:\nIt's sad that everything about this place was great (even the service and decor)...\n\nGOLD:\nservice | positive\ndecor | positive\nsteak | negative\n\nPREDICTED:\nservice | positive\ndecor | positive\nsteak | neutral\n\nâŒ Partial (2/3 matched)\n\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nExample 8\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nTEXT:\nto be honest we only had drinks and appetizers downstairs as we were there for a...\n\nGOLD:\nappetizers | neutral\nstaff | positive\nfood | positive\n\nPREDICTED:\ndrinks | neutral\nstaff | positive\nfood | positive\n\nâŒ Partial (2/3 matched)\n\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nExample 9\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nTEXT:\nThe brasserie-style menu remains relatively unchanged, featuring classic bistro ...\n\nGOLD:\nbrasserie-style menu | neutral\nbistro choices | positive\nfrisee salad with bacon, blue cheese | neutral\na poached egg | neutral\nsteak tartare | neutral\nmoules | neutral\nsteak frites | neutral\nburgers | positive\n\nPREDICTED:\nmenu | positive\nfrisee salad with bacon | neutral\nblue cheese | neutral\npoached egg | neutral\nsteak tartare | neutral\nburgers | neutral\nsandwiches | neutral\n\nâŒ Partial (1/8 matched)\n\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nExample 10\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nTEXT:\nwe all liked the brunch items we had but when we later asked if the chips were s...\n\nGOLD:\nbrunch | positive\nchips | neutral\nwaitress | negative\n\nPREDICTED:\nbrunch items | positive\nchips | neutral\nmeal | neutral\nwaitress | negative\n\nâŒ Partial (2/3 matched)\n\n======================================================================\nGENERATION QUALITY METRICS\n======================================================================\n\n[1/4] Computing ROUGE scores...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading builder script: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7a584d8c6843481393dc873c5a324096"}},"metadata":{}},{"name":"stdout","text":"âœ… ROUGE-1: 0.8495\n   ROUGE-2: 0.7706\n   ROUGE-L: 0.8108\n\n[2/4] Computing BLEU score...\nâœ… BLEU Score: 100.0000\n\n[3/4] Computing METEOR score...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading builder script: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9470d99198d94366a5054e23c59c5af9"}},"metadata":{}},{"name":"stderr","text":"[nltk_data] Downloading package wordnet to /usr/share/nltk_data...\n[nltk_data]   Package wordnet is already up-to-date!\n[nltk_data] Downloading package punkt_tab to /usr/share/nltk_data...\n[nltk_data]   Package punkt_tab is already up-to-date!\n[nltk_data] Downloading package omw-1.4 to /usr/share/nltk_data...\n","output_type":"stream"},{"name":"stdout","text":"âœ… METEOR Score: 0.8419\n\n[4/4] Computing BERTScore...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading builder script: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"70ef1f7b208f441982aa72ae9ff8b8bc"}},"metadata":{}},{"name":"stdout","text":"âš ï¸ BERTScore skipped: To be able to use evaluate-metric/bertscore, you need to install the following dependencies['bert_score'] using 'pip install bert_score' for instance'\n\n======================================================================\nSEMANTIC HALLUCINATION ANALYSIS\n======================================================================\n\n[1/3] Loading semantic model...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"71dae47beaa04cf08052c40efc1ebc79"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"115ac7e069b44ba08686f44f7119ba6d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"README.md: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c12e7d7ed2e14038a15f64dead9cf9e7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9b69d7f807304a41a1fc75c255106a60"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4184c62833f344eaa5210c2c235a8b5a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6f56e685b06d48208ccef670b171d433"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c622987a5706495ea212f0f8e814198f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d24b466eff714e1388d9054c876524aa"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b9e565a8cc6c462a8363b2c30cab7095"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d36b00494eea45ebb1fd70ceb301cc49"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d473b638fb8f4a43909b4f3bf253e754"}},"metadata":{}},{"name":"stdout","text":"âœ“ Semantic model loaded\n\n[2/3] Analyzing hallucinations...\n\nâœ… Semantic Hallucination Analysis:\n   Total generated aspects:           1388\n   Explicit (in text):                960 (69.2%)\n   Implicit but semantically valid:   323 (23.3%)\n   True hallucinations:               105 (7.6%)\n\n   ğŸ“Š Semantic Hallucination Rate:    0.0756 (7.6%)\n   ğŸ“Š Strict Hallucination Rate:      0.3084 (30.8%)\n\n   âš ï¸ Examples of true hallucinations:\n   1. Generated: 'sandwiches' | Gold: ['moules', 'steak frites', 'bistro choices', 'steak tartare', 'a poached egg', 'frisee salad with bacon, blue cheese', 'burgers', 'brasserie-style menu']\n      Text: The brasserie-style menu remains relatively unchanged, featuring classic bistro ...\n   2. Generated: 'meal' | Gold: ['brunch', 'waitress', 'chips']\n      Text: we all liked the brunch items we had but when we later asked if the chips were s...\n   3. Generated: 'snow peas' | Gold: ['glass of wine', 'dessert', 'individual pizzas']\n      Text: A glass of wine for each of us (decent), shared appetizer (snow peas, excellent)...\n\n[3/3] Computing semantic coverage...\n\nâœ… Semantic Coverage Analysis:\n   Total gold aspects:       1336\n   Exact matches:            989 (74.0%)\n   Semantic matches:         117 (8.8%)\n   Missed aspects:           230 (17.2%)\n\n   ğŸ“Š Exact Coverage:        0.7403 (74.0%)\n   ğŸ“Š Semantic Coverage:     0.8278 (82.8%)\n\n======================================================================\nFORMAT ADHERENCE\n======================================================================\n\nâœ… Format Adherence:\n   Valid format: 500/500 (100.0%)\n   Malformed outputs: 0 (0.0%)\n   Empty outputs: 0 (0.0%)\n\n======================================================================\nCOMPREHENSIVE EVALUATION SUMMARY - VANILLA T5 BASELINE\n======================================================================\n\nModel: Vanilla T5-base (Baseline)\nDataset: 500 test samples\n\n======================================================================\nTASK-SPECIFIC METRICS (Primary)\n======================================================================\n\n1. Aspect + Sentiment F1:      0.6067\n2. Aspect-Only F1:              0.7264\n3. Exact Match Accuracy:        0.2880\n4. Sentiment Accuracy:          0.8352\n\n======================================================================\nGENERATION QUALITY METRICS\n======================================================================\n\n5. ROUGE-L:                     0.8108\n6. BLEU:                        100.0000\n7. METEOR:                      0.8419\n\n======================================================================\nRELIABILITY METRICS (Semantic-Aware)\n======================================================================\n\n9. Semantic Hallucination Rate: 0.0756 (7.6%)\n10. Semantic Coverage:          0.8278 (82.8%)\n11. Format Adherence:           1.0000 (100.0%)\n\n======================================================================\nâœ… EVALUATION COMPLETE - VANILLA T5 BASELINE\n======================================================================\n\nğŸ“Š Compare these results with CL T5 model for improvement analysis\n","output_type":"stream"}],"execution_count":3}]}